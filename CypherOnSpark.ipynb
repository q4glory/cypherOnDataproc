{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Cypher on Dataproc Jupyter Notebook\n## Prerequisite\n### 1.0 Dataproc Setup\nCreate a spark 3.0 dataproc with below reference cmd on gcloud, dont use the latest spark image \n\n### 1.1 Spark Packages setup - Spark connector\n```bash\nhadoop fs -copyToLocal gs://dataproc-staging-us-central1-185692258849-ipivnxza/notebooks/jupyter/spark3/spark-bigquery-with-dependencies_2.12-0.18.0.jar /usr/local/share/google/dataproc/lib/\n```\n\n### 1.2 Spark Packages setup - Cypher package\n```bash\nhadoop fs -copyToLocal gs://dataproc-staging-us-central1-185692258849-ipivnxza/notebooks/jupyter/spark3/morpheus-spark-cypher-0.4.2-all.jar /usr/lib/spark/jars/ \n```"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "!hadoop fs -copyToLocal gs://dataproc-staging-us-central1-185692258849-ipivnxza/notebooks/jupyter/spark3/spark-bigquery-with-dependencies_2.12-0.18.0.jar /usr/local/share/google/dataproc/lib/"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": "!hadoop fs -copyToLocal gs://dataproc-staging-us-central1-185692258849-ipivnxza/notebooks/jupyter/spark3/morpheus-spark-cypher-0.4.2-all.jar /usr/lib/spark/jars/ "}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Hello World\nTime: 0.4546999931335449 seconds.\n\n"}], "source": "%%time\nprintln(\"Hello World\")"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"data": {"text/plain": "stopTimesDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [stop_id: bigint, trip_id: bigint ... 7 more fields]\n"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "val stopTimesDF = (spark.read.format(\"bigquery\")\n  .option(\"table\", \"gcp-hk-markii-dis:public_dataset.sf_transit_muni_stop_times\")\n  .option(\"filter\", \"arrives_next_day = false AND dropoff_type = 'regular'\")\n  .load().cache())"}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- stop_id: long (nullable = true)\n |-- trip_id: long (nullable = true)\n |-- stop_sequence: long (nullable = true)\n |-- arrival_time: long (nullable = true)\n |-- arrives_next_day: boolean (nullable = true)\n |-- departure_time: long (nullable = true)\n |-- departs_next_day: boolean (nullable = true)\n |-- dropoff_type: string (nullable = true)\n |-- exact_timepoint: boolean (nullable = true)\n\n"}], "source": "stopTimesDF.createOrReplaceTempView(\"stopTimes\")\nstopTimesDF.printSchema()"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"data": {"text/plain": "stopsDF: org.apache.spark.sql.DataFrame = [id: bigint, stop_number: bigint]\ntripsDF: org.apache.spark.sql.DataFrame = [id: bigint, trip_number: bigint]\ncontainsDF: org.apache.spark.sql.DataFrame = [source: bigint, target: bigint ... 2 more fields]\n"}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": "val stopsDF = spark.sql(\"SELECT DISTINCT stop_id AS id, stop_id AS stop_number FROM stopTimes\")\nval tripsDF = spark.sql(\"SELECT DISTINCT trip_id AS id, trip_id AS trip_number FROM stopTimes\")\nval containsDF = spark.sql(\"SELECT DISTINCT trip_id AS source, stop_id AS target, stop_sequence, \" +\n   \"CONCAT(trip_id, stop_id) AS id FROM stopTimes\")"}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Time: 0.9468436241149902 seconds.\n\n"}, {"data": {"text/plain": "import org.opencypher.morpheus.api.MorpheusSession\nimport org.opencypher.morpheus.api.io.{MorpheusNodeTable, MorpheusRelationshipTable}\nimport spark.sqlContext.implicits._\n"}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "%%time\nimport org.opencypher.morpheus.api.MorpheusSession\nimport org.opencypher.morpheus.api.io.{MorpheusNodeTable, MorpheusRelationshipTable}\nimport spark.sqlContext.implicits._"}, {"cell_type": "code", "execution_count": 14, "metadata": {"scrolled": true}, "outputs": [{"data": {"text/plain": "stopTable: org.opencypher.morpheus.api.io.MorpheusElementTable = MorpheusElementTable(ElementMapping(NodePattern(NODE(:Stop)),Map(PatternElement(node,NODE(:Stop)) -> Map(stop_number -> stop_number)),Map(PatternElement(node,NODE(:Stop)) -> Map(SourceIdKey -> id))),org.opencypher.morpheus.impl.table.SparkTable$DataFrameTable@62f25f1c)\ntripTable: org.opencypher.morpheus.api.io.MorpheusElementTable = MorpheusElementTable(ElementMapping(NodePattern(NODE(:Trip)),Map(PatternElement(node,NODE(:Trip)) -> Map(trip_number -> trip_number)),Map(PatternElement(node,NODE(:Trip)) -> Map(SourceIdKey -> id))),org.opencypher.morpheus.impl.table.SparkTable$DataFrameTable@72c8be3d)\ncontainsTable: org.opencypher.morpheus.api.io.MorpheusElementTable = MorpheusElementTable(ElementMapping(RelationshipPattern(RE...\n"}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": "val stopTable = MorpheusNodeTable(Set(\"Stop\"), stopsDF)\nval tripTable = MorpheusNodeTable(Set(\"Trip\"), tripsDF)\nval containsTable = MorpheusRelationshipTable(\"CONTAINS\", containsDF)"}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"data": {"text/plain": "morpheus: org.opencypher.morpheus.api.MorpheusSession = MorpheusSession\ngraph: org.opencypher.okapi.relational.api.graph.RelationalCypherGraph[org.opencypher.morpheus.impl.table.SparkTable.DataFrameTable] = ScanGraph(NodePattern(NODE(:Stop)), NodePattern(NODE(:Trip)), RelationshipPattern(RELATIONSHIP(:CONTAINS)))\n"}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": "implicit val morpheus: MorpheusSession = MorpheusSession.local()\nval graph = morpheus.readFrom(stopTable, tripTable, containsTable)"}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+---+\n|   trip|seq|\n+-------+---+\n|8961808| 59|\n|8962105| 59|\n|8962102| 59|\n|8961791| 59|\n|8962089| 59|\n|8961822| 59|\n|8961821| 59|\n|8961819| 59|\n|8962069| 59|\n|8961968| 59|\n|8962120| 59|\n|8961942| 59|\n|8961933| 59|\n|8961931| 59|\n|8962079| 59|\n|8961824| 59|\n|8962076| 59|\n|8962075| 59|\n|8961982| 59|\n|8961818| 59|\n+-------+---+\nonly showing top 20 rows\n\n"}, {"data": {"text/plain": "result: org.opencypher.okapi.relational.api.planning.RelationalCypherResult[org.opencypher.morpheus.impl.table.SparkTable.DataFrameTable] = RelationalCypherResult(Some(Select(orderedFields=List(trip :: INTEGER?, seq :: INTEGER?), solved=SolvedQueryModel(Set(seq :: INTEGER?, s1 :: NODE(:Stop) @ session.tmp1, trip :: INTEGER?, t1 :: NODE(:Trip) @ session.tmp1, c1 :: RELATIONSHIP(:CONTAINS) @ session.tmp1),Set(t1:Trip :: BOOLEAN, s1:Stop :: BOOLEAN, c1:CONTAINS :: BOOLEAN, s1.stop_number :: INTEGER? = $  AUTOINT0 :: INTEGER)))),Some(Select(expressions=List(trip :: INTEGER?, seq :: INTEGER?), columnRenames=Map())))\nresultsTable: org.apache.spark.sql.DataFrame = [trip: bigint, seq: bigint]\n"}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": "val result = graph.cypher(\"\"\"\n  |MATCH\n  | (s1:Stop {stop_number: 15104})<-[c1:CONTAINS]-(t1:Trip)\n  |RETURN t1.trip_number AS trip, c1.stop_sequence AS seq\n\"\"\".stripMargin)\nresult.records.table.df.toDF(\"trip\", \"seq\").createOrReplaceTempView(\"results\")\nval resultsTable = spark.sql(\"SELECT * FROM results\")\nresultsTable.show()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "spylon-kernel", "language": "scala", "name": "spylon-kernel"}, "language_info": {"codemirror_mode": "text/x-scala", "file_extension": ".scala", "help_links": [{"text": "MetaKernel Magics", "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"}], "mimetype": "text/x-scala", "name": "scala", "pygments_lexer": "scala", "version": "0.4.1"}}, "nbformat": 4, "nbformat_minor": 4}